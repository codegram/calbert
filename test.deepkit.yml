image: codegram/calbert:latest

docker:
  binds:
    - "~/data:/data"

files:
  - config
  - calbert
  - dist

output:
  - run
  - export
  - models

config:
  version: tiny
  # maxing out 16 GB of GPU ram in a P100
  train_batch_size: 52
  eval_batch_size: 88

command: python -m calbert train --tokenizer-path dist/tokenizer-uncased/ca.uncased.30000.model --train-path /data/calbert/train.txt --valid-path /data/calbert/valid.txt --train-batch-size {{train_batch_size}} --eval-batch-size {{eval_batch_size}} --export-path export --fp16 model={{version}}
